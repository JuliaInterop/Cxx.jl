<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Implementation · Cxx.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Cxx.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" action="search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="index.html">Home</a></li><li><a class="toctext" href="api.html">API</a></li><li><a class="toctext" href="examples.html">Examples</a></li><li class="current"><a class="toctext" href="implementation.html">Implementation</a><ul class="internal"><li><a class="toctext" href="#llvmcall-1"><code>llvmcall</code></a></li><li><a class="toctext" href="#The-@cxx-macro-1">The <code>@cxx</code> macro</a></li><li><a class="toctext" href="#Staged-functions-1">Staged functions</a></li><li><a class="toctext" href="#Implementation-of-the-@cxx-macro-1">Implementation of the <code>@cxx</code> macro</a></li></ul></li><li><a class="toctext" href="repl.html">C++ REPL</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href="implementation.html">Implementation</a></li></ul><a class="edit-page" href="https://github.com/Keno/Cxx.jl/tree/02a606e6dad33a244603ad8a57d5c8f4ce089893/docs/src/implementation.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Implementation</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="How-it-Works:-A-High-Level-Overview-1" href="#How-it-Works:-A-High-Level-Overview-1">How it Works: A High Level Overview</a></h1><p>The two primary Julia features that enable Cxx.jl to work are <code>llvmcall</code> and staged functions.</p><h2><a class="nav-anchor" id="llvmcall-1" href="#llvmcall-1"><code>llvmcall</code></a></h2><p><code>llvmcall</code> allows the user to pass in an LLVM IR expression which will then be embedded directly in the Julia expressions. This functionality could be considered the &quot;inline assembly&quot; equivalent for Julia. However, since all optimizations are run after <code>llvmcall</code> IR has been inlined into the Julia IR, all LLVM optimizations such as constant propagation, dead code elimination, etc. are applied across both sources of IR, eliminating a common inefficiency of using inline (machine code) assembly.</p><p>The primary <code>llvmcall</code> syntax is as follows (reminiscent of the <code>ccall</code> syntax):</p><pre><code class="language-none">llvmcall(&quot;&quot;&quot;%3 = add i32 %1, %0
             ret i32 %3         &quot;&quot;&quot;, Int32, (Int32, Int32), x, y)

         \________________________/ \_____/ \____________/ \___/
              Input LLVM IR            |     Argument Tuple  |
                                   Return Type            Argument</code></pre><p>Behind the scenes, LLVM will take the IR and wrap it in an LLVM function with the given return type and argument types. To call this function, Julia does the same argument translation it would for a <code>ccall</code> (e.g. unboxing <code>x</code> and <code>y</code> if necessary). Afterwards, the resulting call instruction is inlined.</p><p>In this package, however, we use the second form of <code>llvmcall</code>, which differs from the first in that the IR argument is not a string, but a <code>Ptr{Void}</code>. In this case, Julia will skip the wrapping and proceed straight to argument translation and inlining.</p><p>The underlying idea is thus simple: have Clang generate some LLVM IR in memory and then use the second form of LLVM IR to actually call it.</p><h2><a class="nav-anchor" id="The-@cxx-macro-1" href="#The-@cxx-macro-1">The <code>@cxx</code> macro</a></h2><p>The <code>@cxx</code> macro (see above for a description of its usage) thus needs to analyze the expression passed to it and generate an equivalent representation as a Clang AST, compile it, and splice the resulting function pointer into <code>llvmcall</code>. In principle, this is quite straightforward. We simply need to match on the appropriate Julia AST and call the appropriate methods in Clang&#39;s Sema instance to generate the expression. And while it can be tricky to figure out what method to call, the real problem with this approach is types. Since C++ has compile time function overloading based on types, we need to know the argument types to call the function with, so we may select the correct to call. However, since <code>@cxx</code> is a macro, it operates on syntax only and, in particular, does not know the types of the expressions that form the parameters of the C++ function.</p><p>The solution to this is to, as always in computing, add an extra layer of indirection.</p><h2><a class="nav-anchor" id="Staged-functions-1" href="#Staged-functions-1">Staged functions</a></h2><p>Staged functions, also known as generated functions, are similar to macros in that they return expressions rather than values. For example,</p><pre><code class="language-julia">@generated function staged_t1(a, b)
   if a == Int
       return :(a+b)
   else
       return :(a*b)
   end
end
@test staged_t1(1,2) == 3         # a is an Int
@test staged_t1(1.0,0.5) == 0.5   # a is a Float64 (i.e. not an Int)
@test staged_t1(1,0.5) == 1.5     # a is an Int</code></pre><p>Though the example above could have of course been done using regular dispatch, it does illustrate the usage of staged functions: Instead of being passed the values, the staged function is first given the type of the argument and, after some computation, returns an expression that represents the actual body of the function to run.</p><p>An important feature of staged functions is that, though a staged function may be called with abstract types, if the staged function throws an error when passed abstract types, execution of the staged function is delayed until all argument types are known.</p><h2><a class="nav-anchor" id="Implementation-of-the-@cxx-macro-1" href="#Implementation-of-the-@cxx-macro-1">Implementation of the <code>@cxx</code> macro</a></h2><p>We can thus see how macros and staged functions fit together. First, <code>@cxx</code> does some syntax transformation to make sure all the required information is available to the staged function, e.g.</p><pre><code class="language-julia-repl">julia&gt; macroexpand(:(@cxx foo(a, b)))
:(cppcall(CppNNS{(:foo,)}(), a, b))</code></pre><p>Here <code>cppcall</code> is the staged function. Note that the name of the function to call was wrapped as the type parameter to a <code>CppNNS</code> type. This is important, because otherwise the staged function would not have access to the function name (since it&#39;s a symbol rather than a value). With this, <code>cppcall</code> will get the function name and the types of the two parameters, which is all it needs to build up the Clang AST. The expression returned by the staged function will then simply be the <code>llvmcall</code> with the appropriate generated LLVM function, though in some cases we need to return some extra code.</p><footer><hr/><a class="previous" href="examples.html"><span class="direction">Previous</span><span class="title">Examples</span></a><a class="next" href="repl.html"><span class="direction">Next</span><span class="title">C++ REPL</span></a></footer></article></body></html>
